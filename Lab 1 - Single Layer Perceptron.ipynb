{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dfde62e",
   "metadata": {},
   "source": [
    "MarÃ­a Romero Huertas (Erasmus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35bdd30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0        1  2\n",
      "0   0.218350  0.81884  1\n",
      "1   0.141150  0.83535  1\n",
      "2   0.370220  0.81110  1\n",
      "3   0.315650  0.83101  1\n",
      "4   0.364840  0.85180  1\n",
      "5   0.461110  0.82518  1\n",
      "6   0.552230  0.83449  1\n",
      "7   0.169750  0.84049  1\n",
      "8   0.491870  0.80889  1\n",
      "9   0.149130  0.77104 -1\n",
      "10  0.184740  0.62790 -1\n",
      "11  0.088380  0.62068 -1\n",
      "12  0.098166  0.79092 -1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from the file\n",
    "data = pd.read_csv('data1.txt', header=None)\n",
    "\n",
    "# Display the data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ee1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first two columns into matrix X\n",
    "X = data.iloc[:, :-1].values  \n",
    "\n",
    "# Extract the third column into array Y\n",
    "T = data.iloc[:, -1].values   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3edb0c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.21835 , 0.81884 ],\n",
       "        [0.14115 , 0.83535 ],\n",
       "        [0.37022 , 0.8111  ],\n",
       "        [0.31565 , 0.83101 ],\n",
       "        [0.36484 , 0.8518  ],\n",
       "        [0.46111 , 0.82518 ],\n",
       "        [0.55223 , 0.83449 ],\n",
       "        [0.16975 , 0.84049 ],\n",
       "        [0.49187 , 0.80889 ],\n",
       "        [0.14913 , 0.77104 ],\n",
       "        [0.18474 , 0.6279  ],\n",
       "        [0.08838 , 0.62068 ],\n",
       "        [0.098166, 0.79092 ]]),\n",
       " array([ 1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b6fbf",
   "metadata": {},
   "source": [
    "Train single perceptron with two inputs and one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec6cebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0919499198651913, -1.4633506528116793, 1.0817916791983249)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random initial values of w1, w2 and b\n",
    "\n",
    "from numpy.random import randn, seed\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "SEED = 22\n",
    "seed(SEED)\n",
    "\n",
    "# Generate random initial values\n",
    "w1 = randn()\n",
    "w2 = randn()\n",
    "b = randn()\n",
    "\n",
    "w1, w2, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee67707",
   "metadata": {},
   "source": [
    "Calculate weighted sum with randomly generated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b6d6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateErrors(X, T, w1, w2, b):\n",
    "    errors = []\n",
    "    \n",
    "    # Loop over each sample in X\n",
    "    for i, x in enumerate(X):\n",
    "        \n",
    "        # Calculate the output for the data sample\n",
    "        v = x[0] * w1 + x[1] * w2 + b\n",
    "        \n",
    "        # Predict label based on v\n",
    "        if v > 0:\n",
    "            y = 1\n",
    "        else:\n",
    "            y = -1 \n",
    "        \n",
    "        # Calculate the error for the data sample\n",
    "        e = T[i] - y\n",
    "        errors.append(e)\n",
    "    \n",
    "    return errors\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca5bbbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, T, w1, w2, b, ETA):\n",
    "    errors = []\n",
    "    \n",
    "    # Loop over each sample in X\n",
    "    for i, x in enumerate(X):\n",
    "        \n",
    "        # Calculate the output for the data sample\n",
    "        v = x[0] * w1 + x[1] * w2 + b\n",
    "        \n",
    "        # Predict label based on v\n",
    "        if v > 0:\n",
    "            y = 1\n",
    "        else:\n",
    "            y = -1 \n",
    "        \n",
    "        # Calculate the error for the data sample\n",
    "        e = T[i] - y\n",
    "        errors.append(e)\n",
    "        \n",
    "        # Update parameters\n",
    "        w1 = w1 + ETA * e * x[0]\n",
    "        w2 = w2 + ETA * e * x[1]\n",
    "        b = b + ETA * e\n",
    "    \n",
    "    return errors, w1, w2, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109cd153",
   "metadata": {},
   "source": [
    "Split the data in train/test (5 examples for the training split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c70dbcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_EXAMPLES = 5\n",
    "\n",
    "# Manually select the training data because it's a small sample and we need to make sure both classes are included\n",
    "train_index = [0, 1, 2, 11, 12]\n",
    "test_index = [i for i in range(len(X)) if i not in train_index]\n",
    "\n",
    "# Select the first five rows for x_train\n",
    "X_train = X[train_index]\n",
    "\n",
    "# Select the remaining rows for x_test\n",
    "X_test = X[test_index]\n",
    "\n",
    "# Select the first five labels for t_train\n",
    "T_train = T[train_index]\n",
    "\n",
    "# Select the remaining labels for t_test\n",
    "T_test = T[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc098da2",
   "metadata": {},
   "source": [
    "Calculate the total error for these 5 inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7efd5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = calculateErrors(X_train, T_train, w1, w2, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c9d1404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, -2, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17efd1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalAE = sum(abs(e) for e in errors)\n",
    "totalAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41caae6e",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf3f1da",
   "metadata": {},
   "source": [
    "Write the training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6672b21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ETA = 1 #random number between 0 and 1\n",
    "\n",
    "while totalAE != 0:\n",
    "    # Calculate output and errors for current sample and update parameters\n",
    "    errors, w1, w2, b = train(X_train, T_train, w1, w2, b, ETA)\n",
    "    \n",
    "    # Calculate total error for current example\n",
    "    totalAE = sum(abs(e) for e in errors)\n",
    "\n",
    "totalAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cf44681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying training algorithm\n",
      "Total absolute error: 0\n",
      "Updated parameters: w1: 4.78, w2: 3.05, b: -2.92\n"
     ]
    }
   ],
   "source": [
    "print('After applying training algorithm')\n",
    "print('Total absolute error:', totalAE)\n",
    "print(f\"Updated parameters: w1: {round(w1,2)}, w2: {round(w2,2)}, b: {round(b,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4e302",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbbb5469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction Result</th>\n",
       "      <th>Prediction Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction Result  Prediction Error\n",
       "0               True                 0\n",
       "1               True                 0\n",
       "2               True                 0\n",
       "3               True                 0\n",
       "4               True                 0\n",
       "5               True                 0\n",
       "6              False                -2\n",
       "7               True                 0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate the error for each testing example using the updated parameters\n",
    "test_errors = calculateErrors(X_test, T_test, w1, w2, b)\n",
    "\n",
    "prediction_results = [e == 0 for e in test_errors]\n",
    "\n",
    "data = {\n",
    "    'Prediction Result': prediction_results,\n",
    "    'Prediction Error': test_errors\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96c07166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total absolute error for the test: 2\n"
     ]
    }
   ],
   "source": [
    "test_AE = sum(abs(e) for e in test_errors)\n",
    "print('Total absolute error for the test:', test_AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de67e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy (number of correct predictions over total predictions)\n",
    "accuracy = sum(prediction_results) / len(prediction_results) * 100\n",
    "\n",
    "# Display the accuracy\n",
    "print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590cf800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
